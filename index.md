---
layout:     page
title:
permalink:  /
---

<div class="row">
    <div class="col-sm-6 col-xs-12">
        <img src="/img/Algonquin.jpg">
    </div>
    <div class="col-sm-6 col-xs-12" style="margin-bottom: 0;">
        PhD Candidate in Statistical Machine Learning<br>        
        Dept. of Computing Science, <a href="http://rlai.ualberta.ca/">RLAI</a> & <a href="https://www.amii.ca/">AMII</a> <br>
        <a href="https://www.ualberta.ca/computing-science/index.html">University of Alberta</a><br>
        gauthamv dot 529 at gmail dot com
    </div>
</div>
<hr>


<a name="/bio"></a>
# About Me

I read. I write. I build stuff. 

**I'm interested in building machines with human-like intelligence.**
My research lies in the overlapping areas of _Artificial Intelligence_ and _Robotics_. I actively work on the design and development of _Reinforcement Learning ([RL][RL-wiki])_ algorithms and _continual learning_ systems for real-world robots. I also have a strong side interest in _Neuroscience_, _Evolutionary Biology_ and _Quantum Computing_. All are a part of an overarching goal to understand the emergence of intelligence.  <br>

---

<div class="row" id="timeline-logos">
    <div class="col-xs-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a href="https://www.nitt.edu/"><img src="/img/logos/NITT_logo.png"></a>
        </div>
        <div class="logo-desc">
            NIT Trichy<br>
            2011 - 2015
        </div>
    </div>
    <div class="col-xs-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a href="https://www.iiit.ac.in/"><img style="width:125px;" src="/img/logos/iiit-h_logo.png"></a>
        </div>
        <div class="logo-desc">
            Robotics Research Center, IIIT Hyderabad<br>
            Summer 2014
        </div>
    </div>
    <div class="col-xs-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a href="https://www.kindred.ai/"><img src="/img/logos/Kindred/Kindred_Logomark_RGB_Fire.png"></a>
        </div>
        <div class="logo-desc">
            Kindred Systems Inc<br>
            2017 - 2020
        </div>
    </div>
    <div class="col-xs-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a target="_blank" href="https://www.ualberta.ca/index.html"><img style="width:120px;" src="/img/logos/UofA_logo.png"></a>
        </div>
        <div class="logo-desc">
            University of Alberta<br>
            2015 - 2017<br>
            2020 - Present
        </div>
    </div>
</div>

I'm a PhD candidate in Statistical Machine Learning at the University of Alberta. I work under the supervision of [Rupam Mahmood][5] as a part of the Reinforcement Learning and Artificial Intelligence ([RLAI](RLAI)) Group.  

Previously, I was a Machine Learning Researcher at [Kindred Systems Inc][3]. As a part of the AI Research Team in Toronto, I developed Deep Reinforcement Learning techniques to improve the product's ([SORT](SORT)) overall throughput at e-commerce fulfillment centres like [Gap Inc](GAP), etc. I was also responsible for the design, implementation and evaluation of learning algorithms and robot infrastructure as a part of the research and publication efforts at Kindred (e.g., [SenseAct](SenseAct)). 

I graudated with an M.Sc (Thesis) in Computing Science from the University of Alberta in 2017. I worked under the supervision of [Patrick M. Pilarski][4] as a part of the [BLINC](BLINC) and [RLAI](RLAI) labs. As a part of my masters, I mostly worked with rehabilitative and assistive robots. My thesis research was on _‟Teaching a Powered Prosthetic Arm with an Intact Arm Using Reinforcement Learning”_. We used ideas from _Learning from Demonstration, Actor-Critic Reinforcement Learning_ and explored the possibilities for synergistic, context-aware control of a prosthetic arm. This work won the _2017 M.Sc. Outstanding Thesis Award in Computing Science_.

In a past life, I studied _Instrumentation and Control Engineering_ at the National Institute of Technology (NIT), Tiruchirappalli. Under the guidance of Prof. G. Saravana Ilango, my team devised control strategies for an autonomous robotic vacuum cleaner for solar panels which garnered accolades at the Texas Instruments Innovation Challenge (2014). In addition, I evaluated methods for model predictive control, real-time trajectory generation and motion planning for quadcopters while working with [K. Madhava Krishna][9] and [V. Sankaranarayanan][8].


I also maintain an academic blog titled [Machinae Animatae][tech-blog] and a personal blog titled [Musings of an Enlightened Idiot][blog]

Devices animated


My CV is available [here](#)





---

<a name="/publications"></a>

# Publications

<a name="/visdial-bert"></a>
<h2 class="pubt">Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline</h2>
<p class="pubd">
    <span class="authors">Vishvak Murahari, Dhruv Batra, Devi Parikh, Abhishek Das</span><br>
    <span class="conf">ECCV 2020</span><br>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1912.02379">Paper</a>
        <a target="_blank" href="https://github.com/vmurahari3/visdial-bert">Code</a>
    </span>
</p>
<img src="/img/visdial/visdial-bert.png">
<hr>

<a name="/talks"></a>

# Talks

<div class="row">
    <div class="col-xs-6">
        <p class="talkd">
            <img src="/img/talks/visdial_rl_iccv17.jpg">
        </p>
    </div>
    <div class="col-xs-6">
        <p class="talkd">
            <img src="/img/talks/embodiedqa_cvpr18_4.jpg">
        </p>
    </div>
</div>
<div class="row">
    <div class="col-xs-12">
        <div class="talkt">
            <a target="_blank" href="https://slideslive.com/38917625/tarmac-targeted-multiagent-communication">
                ICML 2019 Imitation, Intent, and Interaction Workshop:
                Targeted Multi-Agent Communication
            </a>
        </div>
        <div class="talkt">
            <a target="_blank" href="https://www.facebook.com/icml.imls/videos/444326646299556/">
                ICML 2019 Oral: Targeted Multi-Agent Communication
            </a>
        </div>
    </div>
</div>
<hr>

<a name="/projects"></a>

# Side projects

<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="http://aideadlin.es">aideadlin.es</a></h2>
        <p class="talkd">
            aideadlin.es is a webpage to keep track of CV/NLP/ML/AI conference deadlines. It's hosted on GitHub, and countdowns are automatically updated via pull requests to the data file in the repo.
            <a target="_blank" href="http://aideadlin.es"><img style="margin-top: 10px;" src="/img/projects/ai-deadlines-1547012831.png"></a>
        </p>
    </div>
</div>

<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/abhshkdz/neural-vqa-attention">neural-vqa-attention</a></h2>
        <p class="talkd">
            Torch implementation of an attention-based visual question answering model (Yang et al., CVPR16).
            The model looks at an image, reads a question, and comes up with an answer to the question and a heatmap of where it looked in the image to answer it.
            Some results <a href="https://computing.ece.vt.edu/~abhshkdz/neural-vqa-attention/figures/">here</a>.
            <a target="_blank" href="https://github.com/abhshkdz/neural-vqa-attention"><img class="project-img" src="/img/projects/neural-vqa-attention.jpg"></a>
        </p>
    </div>
</div>

<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/abhshkdz/neural-vqa">neural-vqa</a></h2>
        <p class="talkd">
            neural-vqa is an efficient, GPU-based Torch implementation of the visual question answering model from the NIPS 2015 paper 'Exploring Models and Data for Image Question Answering' by Ren et al.
            <a target="_blank" href="https://github.com/abhshkdz/neural-vqa"><img src="/img/projects/neural-vqa.jpg"></a>
        </p>
    </div>
</div>





<script src="/js/jquery.min.js"></script>
<script type="text/javascript">
    $('ul:gt(0) li:gt(12)').hide();
    $('#read-more-button > a').click(function() {
        $('ul:gt(0) li:gt(12)').show();
        $('#read-more-button').hide();
    });
</script>

---

[1]: https://www.nitt.edu/
[2]: https://www.ualberta.ca/index.html
[3]: https://www.kindred.ai/
[4]: https://sites.ualberta.ca/~pilarski/
[5]: https://armahmood.github.io/
[6]: https://sites.ualberta.ca/~pilarski/docs/theses/Vasan_Gautham_201709_MSc.pdf
[7]: http://www.incompleteideas.net/
[8]: https://www.nitt.edu/home/academics/departments/eee/people/faculty/prof/sankar/
[9]: https://scholar.google.com/citations?user=QDuPGHwAAAAJ&hl=en
[RL-wiki]: https://en.wikipedia.org/wiki/Reinforcement_learning
[RL-book]: http://www.incompleteideas.net/book/the-book.html
[SORT]: https://www.kindred.ai/products
[GAP]: https://www.gapinc.com/en-us/
[SenseAct]: https://www.kindred.ai/senseact/
[RLAI]: http://rlai.ualberta.ca/
[AMII]: https://www.amii.ca/
[BLINC]: https://blinclab.ca/
[blog]: https://enlightenedidiot.net/
[tech-blog]: #